{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow import set_random_seed\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "import numpy as np\n",
    "from numpy.random import seed\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import ai_metrics as metrics\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "seed(1)\n",
    "set_random_seed(2)\n",
    "\n",
    "class KerasDenseMLP:\n",
    "\n",
    "    def __init__(self, processor,NEURONS,LR,HOURS,EPOCH,BATCH):\n",
    "\n",
    "        self.processor = processor\n",
    "\n",
    "        self.hours = HOURS\n",
    "        self.batch  = BATCH\n",
    "        self.neurons = NEURONS\n",
    "        self.learning = LR\n",
    "        self.epochs = EPOCH\n",
    "\n",
    "        self.checkpoint = \"mlp_\" + str(len(self.neurons)) + \"_layers_\" + str(self.hours) + \"_hours_checkpoint.keras\"\n",
    "\n",
    "        #self.processor.generate_validation_data()\n",
    "        self.model = keras.Sequential()\n",
    "\n",
    "        \"\"\"\n",
    "            Adds an input layer containing the number of attributes specified along with the -i flag\n",
    "          and having the hyperbolic tangent as the activation function.\n",
    "            Considering a neuron list with the format [4,5], its output shape ought to be (*, 4).\n",
    "        \"\"\"\n",
    "        self.model.add(keras.layers.Dense(\n",
    "          units=self.neurons[0],\n",
    "          activation=\"tanh\",\n",
    "          input_shape=(self.processor.n_inputs,)\n",
    "        ))\n",
    "\n",
    "        \"\"\"\n",
    "            Adds hidden layers containing units according to the value supplied with the -n flag\n",
    "          e.g. -n 4 5 yields a list [4,5] therefore two hidden layers will be added. The former\n",
    "          having 4 neurons and the latter 5 neurons.\n",
    "            Their output shapes ought to be respectively (*, 5) and (*, args.output).\n",
    "        \"\"\"\n",
    "        for key, neurons in enumerate(self.neurons):\n",
    "            if key < len(self.neurons) - 1:\n",
    "                self.model.add(keras.layers.Dense(units=self.neurons[key+1], activation=\"tanh\"))\n",
    "            else:\n",
    "                self.model.add(keras.layers.Dense(units=self.processor.n_outputs, activation=\"tanh\"))\n",
    "\n",
    "        \"\"\"\n",
    "            Adds output input layer containing the number of attributes specified along with the -o flag\n",
    "          and having the linear function as the activation function.\n",
    "            Its output shape ought to be (*, args.output).\n",
    "        \"\"\"\n",
    "        self.model.add(keras.layers.Dense(units=self.processor.n_outputs))\n",
    "\n",
    "        print(self.model.summary())\n",
    "        self.model.compile(\n",
    "          optimizer=keras.optimizers.RMSprop(lr=self.learning),\n",
    "          loss=keras.losses.MSE,\n",
    "          metrics=[\n",
    "            keras.metrics.MAE\n",
    "          ]\n",
    "        )\n",
    "\n",
    "    def train(self):\n",
    "        checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "          filepath=self.checkpoint,\n",
    "          monitor=\"val_loss\",\n",
    "          verbose=1,\n",
    "          save_weights_only=True,\n",
    "          save_best_only=True\n",
    "        )\n",
    "        early_stopping = keras.callbacks.EarlyStopping(\n",
    "          monitor=\"val_loss\",\n",
    "          patience=10,\n",
    "          min_delta=1e-4,\n",
    "          mode='auto',\n",
    "          verbose=1\n",
    "        )\n",
    "        reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.1,\n",
    "            min_lr=1e-4,\n",
    "            patience=0,\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        callbacks = [\n",
    "          checkpoint, early_stopping, reduce_lr\n",
    "        ]\n",
    "\n",
    "        history = self.model.fit(\n",
    "          x=self.processor.x_train_scaled,\n",
    "          y=self.processor.y_train,\n",
    "          epochs=self.epochs,\n",
    "          validation_split=self.processor.validation_split\n",
    "        )\n",
    "\n",
    "        plt.plot(history.history['loss'], label='train')\n",
    "        plt.plot(history.history['val_loss'], label='validation')\n",
    "        plt.legend()\n",
    "        plt.savefig(\"loss.png\")\n",
    "\n",
    "    def evaluate(self):\n",
    "        result = self.model.evaluate(x=self.processor.x_test_scaled, y=self.processor.y_test)\n",
    "\n",
    "        for res, metric in zip(result, self.model.metrics_names):\n",
    "            print(\"{0}: {1:.3e}\".format(metric, res))\n",
    "\n",
    "    def predict(self):\n",
    "        x = self.processor.x_test_scaled\n",
    "        y = self.processor.y_test\n",
    "\n",
    "        y_test = self.model.predict(x)\n",
    "\n",
    "        # For each output-signal.\n",
    "        for signal in range(len(self.processor.target_names)):\n",
    "            # Get the output-signal predicted by the model.\n",
    "            signal_pred = y_test[:, signal]\n",
    "\n",
    "            # Get the true output-signal from the data-set.\n",
    "            signal_true = y[:, signal]\n",
    "            \n",
    "            plt.clf()\n",
    "            # Plot and compare the two signals.\n",
    "            plt.plot(signal_true, label='Measured')\n",
    "            plt.plot(signal_pred, label='Prediction')\n",
    "\n",
    "            # Plot labels etc.\n",
    "            plt.ylabel(self.processor.target_names[signal])\n",
    "            plt.legend()\n",
    "            plt.savefig(\"prediction_\"+self.processor.target_names[signal]+\".png\")\n",
    "    \n",
    "    \"\"\"\n",
    "    def predict(self):\n",
    "      print(\"predict\")\n",
    "\n",
    "      y_reshaped, y_real = None, self.processor.rescale(self.prediction_X[:,4].reshape(len(self.prediction_X), 1), self.prediction_X)\n",
    "\n",
    "      for hour in range(self.hours):\n",
    "        self.prediction_X = self.prediction_X[1:] if hour > 1 else self.prediction_X[0:]\n",
    "        y_output = self.model.predict(self.prediction_X)\n",
    "\n",
    "        self.prediction_X[:,4] = y_output.reshape(len(y_output))\n",
    "\n",
    "        y_reshaped = self.processor.rescale(y_output, self.prediction_X)\n",
    "      \n",
    "      index_ = self.hours-2 if self.hours > 1 else 0\n",
    "      rmse = sqrt(mean_squared_error(y_reshaped, y_real[index_:]))\n",
    "      print('RMSE: %.3f' % rmse)\n",
    "\n",
    "      y = np.zeros(y_real.shape)\n",
    "      np.put(y, np.indices(y.shape), np.nan)\n",
    "      starting_index = len(y) - len(y_reshaped)\n",
    "\n",
    "      np.put(y, np.indices(y.shape)[:,starting_index:],y_reshaped)\n",
    "\n",
    "      plt.plot(y, label='predicted')\n",
    "      plt.plot(y_real, label='measured')\n",
    "      plt.legend()\n",
    "      plt.show()\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
